{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82128a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Lambda\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac37e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_path = os.path.join('configs', 'voc_classes.txt')\n",
    "anchors_path = os.path.join('configs', 'tiny_yolo3_anchors.txt')\n",
    "weights_path = os.path.join('weights', 'tiny_yolo3_mobilenet_lite_416_voc.h5')\n",
    "class_thresh = 0.3\n",
    "iou = 0.5\n",
    "model_input_shape = (416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLO():\n",
    "    @classmethod\n",
    "\n",
    "    def __init__(self):\n",
    "        self.class_names = get_classes(classes_path)\n",
    "        self.anchors = get_anchors(anchors_path)\n",
    "        self.colors = get_colors(len(self.class_names))\n",
    "        self.inference_model = self.generate_model()\n",
    "\n",
    "    def generate_model(self):\n",
    "        '''to generate the bounding boxes'''\n",
    "        weights_path = os.path.expanduser(weights_path)\n",
    "        assert weights_path.endswith('.h5'), 'Keras model weights must be a .h5 file.'\n",
    "\n",
    "        # Load model, or construct model and load weights.\n",
    "        num_anchors = len(self.anchors)\n",
    "        num_classes = len(self.class_names)\n",
    "        #YOLOv3 model has 9 anchors and 3 feature layers but\n",
    "        #Tiny YOLOv3 model has 6 anchors and 2 feature layers,\n",
    "        #so we can calculate feature layers number to get model type\n",
    "        num_feature_layers = num_anchors//3\n",
    "\n",
    "        inference_model = get_yolo3_inference_model(self.model_type, self.anchors, num_classes, weights_path=weights_path, input_shape=self.model_input_shape + (3,), confidence=self.score, iou_threshold=self.iou)\n",
    "\n",
    "        inference_model.summary()\n",
    "        return inference_model\n",
    "\n",
    "    def predict(self, image_data, image_shape):\n",
    "        out_boxes, out_scores, out_classes = self.inference_model.predict([image_data, image_shape])\n",
    "\n",
    "        out_boxes = out_boxes[0]\n",
    "        out_scores = out_scores[0]\n",
    "        out_classes = out_classes[0]\n",
    "\n",
    "        out_boxes = out_boxes.astype(np.int32)\n",
    "        out_classes = out_classes.astype(np.int32)\n",
    "        return out_boxes, out_classes, out_scores\n",
    "\n",
    "    def detect_image(self, image):\n",
    "        if self.model_input_shape != (None, None):\n",
    "            assert self.model_input_shape[0]%32 == 0, 'Multiples of 32 required'\n",
    "            assert self.model_input_shape[1]%32 == 0, 'Multiples of 32 required'\n",
    "\n",
    "        image_data = preprocess_image(image, self.model_input_shape)\n",
    "\n",
    "        # prepare origin image shape, (height, width) format\n",
    "        image_shape = np.array([image.size[1], image.size[0]])\n",
    "        image_shape = np.expand_dims(image_shape, 0)\n",
    "\n",
    "        start = time.time()\n",
    "        out_boxes, out_classes, out_scores = self.predict(image_data, image_shape)\n",
    "        end = time.time()\n",
    "        print('Found {} boxes in {}'.format(len(out_boxes), 'the image'))\n",
    "        print(\"Inference time: {:.8f} secs\".format(end - start))\n",
    "\n",
    "        #draw result on input image\n",
    "        image_array = np.array(image, dtype='uint8')\n",
    "        image_array = draw_boxes(image_array, out_boxes, out_classes, out_scores, self.class_names, self.colors)\n",
    "\n",
    "        out_classnames = [self.class_names[c] for c in out_classes]\n",
    "        return Image.fromarray(image_array), out_boxes, out_classnames, out_scores\n",
    "\n",
    "    def dump_model_file(self, output_model_file):\n",
    "        self.inference_model.save(output_model_file)\n",
    "\n",
    "    def dump_saved_model(self, saved_model_path):\n",
    "        model = self.inference_model\n",
    "        os.makedirs(saved_model_path, exist_ok=True)\n",
    "\n",
    "        tf.keras.experimental.export_saved_model(model, saved_model_path)\n",
    "        print('export inference model to %s' % str(saved_model_path))\n",
    "\n",
    "\n",
    "\n",
    "def detect_video(yolo, video_path, output_path=\"\"):\n",
    "    import cv2\n",
    "    \n",
    "    vid = cv2.VideoCapture(0 if video_path == '0' else video_path)\n",
    "    \n",
    "    if not vid.isOpened():\n",
    "        raise IOError(\"Couldn't open webcam or video\")\n",
    "        \n",
    "    print(\"CAP_PROP_FPS : '{}'\".format(vid.get(cv2.CAP_PROP_FPS)))\n",
    "    print(\"CAP_PROP_POS_MSEC : '{}'\".format(vid.get(cv2.CAP_PROP_POS_MSEC)))\n",
    "    print(\"CAP_PROP_FRAME_COUNT  : '{}'\".format(vid.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "    accum_time = 0\n",
    "    curr_fps = 0\n",
    "    fps = \"FPS: ??\"\n",
    "    prev_time = timer()\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = vid.read()\n",
    "\n",
    "        if ret != True:\n",
    "            print('Stream end !')\n",
    "            break\n",
    "\n",
    "        image = Image.fromarray(frame)\n",
    "        image, _, _, _ = yolo.detect_image(image)\n",
    "        result = np.asarray(image)\n",
    "        curr_time = timer()\n",
    "        exec_time = curr_time - prev_time\n",
    "        prev_time = curr_time\n",
    "        accum_time = accum_time + exec_time\n",
    "        curr_fps = curr_fps + 1\n",
    "        if accum_time > 1:\n",
    "            accum_time = accum_time - 1\n",
    "            fps = \"FPS: \" + str(curr_fps)\n",
    "            curr_fps = 0\n",
    "        cv2.putText(result, text=fps, org=(3, 15), fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    fontScale=0.50, color=(255, 0, 0), thickness=2)\n",
    "        cv2.namedWindow(\"result\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"result\", result)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Release everything if job is finished\n",
    "    vid.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def detect_img(yolo):\n",
    "    while True:\n",
    "        img = input('Input image filename:')\n",
    "        try:\n",
    "            image = Image.open(img).convert('RGB')\n",
    "        except:\n",
    "            print('Open Error! Try again!')\n",
    "            continue\n",
    "        else:\n",
    "            r_image, _, _, _ = yolo.detect_image(image)\n",
    "            r_image.show()\n",
    "\n",
    "\n",
    "\n",
    "def get_yolo3_inference_model(model_type, anchors, num_classes, weights_path=None, input_shape=None, confidence=0.1, iou_threshold=0.4):\n",
    "    '''create the inference model, for YOLOv3'''\n",
    "    num_anchors = len(anchors)\n",
    "    #YOLOv3 model has 9 anchors and 3 feature layers but\n",
    "    #Tiny YOLOv3 model has 6 anchors and 2 feature layers,\n",
    "    #so we can calculate feature layers number to get model type\n",
    "    num_feature_layers = num_anchors//3\n",
    "\n",
    "    image_shape = Input(shape=(2,), dtype='int64', name='image_shape')\n",
    "\n",
    "    model_body, _ = get_yolo3_model(model_type, num_feature_layers, num_anchors, num_classes, input_shape=input_shape)\n",
    "    print('Create {} YOLOv3 {} model with {} anchors and {} classes.'.format('Tiny' if num_feature_layers==2 else '', model_type, num_anchors, num_classes))\n",
    "\n",
    "    if weights_path:\n",
    "        model_body.load_weights(weights_path, by_name=False)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "\n",
    "    boxes, scores, classes = Lambda(batched_yolo3_postprocess, name='yolo3_postprocess',\n",
    "            arguments={'anchors': anchors, 'num_classes': num_classes, 'confidence': confidence, 'iou_threshold': iou_threshold, 'elim_grid_sense': elim_grid_sense})(\n",
    "        [*model_body.output, image_shape])\n",
    "    model = Model([model_body.input, image_shape], [boxes, scores, classes])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_yolo3_model(model_type, num_feature_layers, num_anchors, num_classes, input_tensor=None, input_shape=None):\n",
    "    #prepare input tensor\n",
    "    if input_shape:\n",
    "        input_tensor = Input(shape=input_shape, name='image_input')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        input_tensor = Input(shape=(None, None, 3), name='image_input')\n",
    "\n",
    "    #Tiny YOLOv3 model has 6 anchors and 2 feature layers\n",
    "    if num_feature_layers == 2:\n",
    "        if model_type in yolo3_tiny_model_map:\n",
    "            model_function = yolo3_tiny_model_map[model_type][0]\n",
    "            backbone_len = yolo3_tiny_model_map[model_type][1]\n",
    "            weights_path = yolo3_tiny_model_map[model_type][2]\n",
    "\n",
    "            if weights_path:\n",
    "                model_body = model_function(input_tensor, num_anchors//2, num_classes, weights_path=weights_path)\n",
    "            else:\n",
    "                model_body = model_function(input_tensor, num_anchors//2, num_classes)\n",
    "        else:\n",
    "            raise ValueError('This model type is not supported now')\n",
    "\n",
    "    #YOLOv3 model has 9 anchors and 3 feature layers\n",
    "    elif num_feature_layers == 3:\n",
    "        if model_type in yolo3_model_map:\n",
    "            model_function = yolo3_model_map[model_type][0]\n",
    "            backbone_len = yolo3_model_map[model_type][1]\n",
    "            weights_path = yolo3_model_map[model_type][2]\n",
    "\n",
    "            if weights_path:\n",
    "                model_body = model_function(input_tensor, num_anchors//3, num_classes, weights_path=weights_path)\n",
    "            else:\n",
    "                model_body = model_function(input_tensor, num_anchors//3, num_classes)\n",
    "        else:\n",
    "            raise ValueError('This model type is not supported now')\n",
    "    else:\n",
    "        raise ValueError('model type mismatch anchors')\n",
    "\n",
    "    return model_body, backbone_len\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3076f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # get wrapped inference object, you can also try \"YOLO\" here ;)\n",
    "    yolo = YOLO()\n",
    "\n",
    "    if inp = 'image':\n",
    "        detect_img(yolo)\n",
    "    elif inp = 'video':\n",
    "        detect_video(yolo, args.input, args.output)\n",
    "    else:\n",
    "        print(\"Specify video input path or image input path\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
