{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0afbc37",
   "metadata": {},
   "source": [
    "## One Node Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f6b2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Librairies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, InputLayer, Reshape, Rescaling\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Uncomment next line to : Force using CPU only by making GPU invisible\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "396785c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n(x_train, y_train), (x_test, y_test) = load_dataset()\\nprint(x_test.shape)\\nplt.imshow(x_train[0])\\nplt.show()\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing & Preprocessing CIFAR-10 Dataset from Directory\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "trainval_path = 'C:/Users/PC/Desktop/DATASET/CIFAR-10/'\n",
    "test_path = ''\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "\n",
    "def load_dataset():\n",
    "    # Loading Training Dataset\n",
    "    x_train = 0\n",
    "    y_train = 0\n",
    "    i = 1    \n",
    "    while i <= 5:\n",
    "        filename = 'data_batch_' + str(i)\n",
    "        fullpath = os.path.join(trainval_path, filename)\n",
    "        data_batch = unpickle(fullpath)\n",
    "        x = data_batch[b'data']\n",
    "        y = data_batch[b'labels']\n",
    "        x = x.reshape(len(x), 3, img_height, img_width).transpose(0, 2, 3, 1)\n",
    "        x = x/255.0\n",
    "        if i==1:\n",
    "            x_train = x\n",
    "            y_train = y\n",
    "        else:\n",
    "            x_train = np.concatenate((x_train, x))\n",
    "            y_train = np.concatenate((y_train, y))\n",
    "        i = i + 1\n",
    "    \n",
    "    # Loading Test/Validation Dataset\n",
    "    fullpath = os.path.join(trainval_path, 'test_batch')\n",
    "    data_batch = unpickle(fullpath)\n",
    "    x_test = data_batch[b'data']\n",
    "    x_test = x_test.reshape(len(x_test), 3, img_height, img_width).transpose(0, 2, 3, 1)\n",
    "    y_test = data_batch[b'labels']\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    # Normalizing Images\n",
    "    x_train, x_test = normalize_images(x_train, x_test)\n",
    "    # Convert to Categorical\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "def normalize_images(train, test):\n",
    "    # convert 0-255 integers to floats\n",
    "    train_norm = train.astype('float32')\n",
    "    test_norm = test.astype('float32')\n",
    "    # scaling values from 0-255 to 0-1\n",
    "    train_norm = train_norm / 255.0\n",
    "    test_norm = test_norm / 255.0\n",
    "    # return normalized images\n",
    "    return train_norm, test_norm\n",
    "\n",
    "\n",
    "\n",
    "'''TEST IF DATASET IS LOADED CORRECTLY'''\n",
    "'''\n",
    "(x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "print(x_test.shape)\n",
    "plt.imshow(x_train[0])\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e5cf1ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_28 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " batch_normalization_36 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_37 (Bat  (None, 32, 32, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 16, 16, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_40 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_41 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 4, 4, 256)         0         \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               2097664   \n",
      "                                                                 \n",
      " batch_normalization_43 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 512)              2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,109,642\n",
      "Trainable params: 4,105,290\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Compile Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=[accuracy])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf21578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Topless Pre-trained VGG16 Model on ImageNet\n",
    "model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "# Adding Classifier Layers\n",
    "x = model.output\n",
    "fl = Flatten()(x)\n",
    "fc1 = Dense(1024, activation='relu')(fl)\n",
    "out = Dense(20, activation='softmax')(fc1)\n",
    "# Concatenate Model\n",
    "model = Model(inputs=model.input, outputs=out)\n",
    "\n",
    "# Let all layers trainable (Fine tuning Total)\n",
    "for layer in model.layers[:-2]:\n",
    "   layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7056905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks - variable learning rate\n",
    "initial_learning_rate = 0.01\n",
    "lr_schedule_cb = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=20, decay_rate=0.96, staircase=True)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"model.h5\", save_best_only=True)\n",
    "\n",
    "# callback - early stopping\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648d42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 27s 31ms/step - loss: 1.9766 - sparse_categorical_accuracy: 0.3465 - val_loss: 2.9171 - val_sparse_categorical_accuracy: 0.1704\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.3551 - sparse_categorical_accuracy: 0.5125 - val_loss: 2.7909 - val_sparse_categorical_accuracy: 0.2524\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 1.1272 - sparse_categorical_accuracy: 0.6053 - val_loss: 2.4255 - val_sparse_categorical_accuracy: 0.3135\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.9757 - sparse_categorical_accuracy: 0.6607 - val_loss: 2.0054 - val_sparse_categorical_accuracy: 0.3819\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 25s 32ms/step - loss: 0.8755 - sparse_categorical_accuracy: 0.6989 - val_loss: 2.6461 - val_sparse_categorical_accuracy: 0.3100\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 25s 31ms/step - loss: 0.7972 - sparse_categorical_accuracy: 0.7272 - val_loss: 2.6166 - val_sparse_categorical_accuracy: 0.3128\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 24s 31ms/step - loss: 0.7430 - sparse_categorical_accuracy: 0.7485 - val_loss: 2.2304 - val_sparse_categorical_accuracy: 0.3840\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - ETA: 0s - loss: 0.6951 - sparse_categorical_accuracy: 0.7654"
     ]
    }
   ],
   "source": [
    "# Training and Evaluating Model\n",
    "# load CIFAR-10 Dataset\n",
    "(x_train, y_train), (x_test, y_test) = load_dataset()\n",
    "# Data Augmentation Generator\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            validation_split=0.2)\n",
    "datagen.fit(x_train)\n",
    "# Data iterator\n",
    "iter_train = datagen.flow(x_train, y_train, batch_size=64)\n",
    "# Calculating Steps par Epoch\n",
    "steps = int(len(x_train) / 64)\n",
    "# Training the model\n",
    "history = model.fit(iter_train, validation_data=(x_test, y_test), steps_per_epoch=steps, epochs=100)\n",
    "score = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77738c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training and validation accuracy\n",
    "plt.plot(history.history['sparse_categorical_accuracy'])\n",
    "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "# plot training and validation loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec63bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12419bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
